{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871393, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Location</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000000</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_044368</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Road Taken</td>\n",
       "      <td>Rona Jaffe</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Mira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_000001</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_081205</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Macbeth (New Penguin Shakespeare)</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_000002</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_086781</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Waverley (Penguin English Library)</td>\n",
       "      <td>Walter Scott</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_000003</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_098622</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Mother Earth Father Sky</td>\n",
       "      <td>Sue Harrison</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Avon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_000004</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_180810</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>She Who Remembers</td>\n",
       "      <td>Linda Lay Shuler</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Signet Book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID     User-ID      Book-ID  Book-Rating   Age   \n",
       "0  TRAIN_000000  USER_00000  BOOK_044368            8  23.0  \\\n",
       "1  TRAIN_000001  USER_00000  BOOK_081205            8  23.0   \n",
       "2  TRAIN_000002  USER_00000  BOOK_086781            0  23.0   \n",
       "3  TRAIN_000003  USER_00000  BOOK_098622            0  23.0   \n",
       "4  TRAIN_000004  USER_00000  BOOK_180810            8  23.0   \n",
       "\n",
       "                           Location                          Book-Title   \n",
       "0  sackville, new brunswick, canada                          Road Taken  \\\n",
       "1  sackville, new brunswick, canada   Macbeth (New Penguin Shakespeare)   \n",
       "2  sackville, new brunswick, canada  Waverley (Penguin English Library)   \n",
       "3  sackville, new brunswick, canada             Mother Earth Father Sky   \n",
       "4  sackville, new brunswick, canada                   She Who Remembers   \n",
       "\n",
       "           Book-Author  Year-Of-Publication      Publisher  \n",
       "0           Rona Jaffe               2001.0           Mira  \n",
       "1  William Shakespeare               1981.0  Penguin Books  \n",
       "2         Walter Scott               1981.0  Penguin Books  \n",
       "3         Sue Harrison               1991.0           Avon  \n",
       "4     Linda Lay Shuler               1989.0    Signet Book  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('open/train.csv')\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159621, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Location</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>USER_00008</td>\n",
       "      <td>BOOK_047966</td>\n",
       "      <td>37.0</td>\n",
       "      <td>vermilion, ohio, usa</td>\n",
       "      <td>Birds of Prey: A Novel of Suspense</td>\n",
       "      <td>J.A. Jance</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Avon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>USER_00008</td>\n",
       "      <td>BOOK_119494</td>\n",
       "      <td>37.0</td>\n",
       "      <td>vermilion, ohio, usa</td>\n",
       "      <td>Midnight Voices</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>USER_00008</td>\n",
       "      <td>BOOK_151775</td>\n",
       "      <td>37.0</td>\n",
       "      <td>vermilion, ohio, usa</td>\n",
       "      <td>Breaking Free : A Prescription for Personal an...</td>\n",
       "      <td>David M.  Noer</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Jossey-Bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>USER_00008</td>\n",
       "      <td>BOOK_176255</td>\n",
       "      <td>37.0</td>\n",
       "      <td>vermilion, ohio, usa</td>\n",
       "      <td>Bitter Harvest</td>\n",
       "      <td>Ann Rule</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>USER_00008</td>\n",
       "      <td>BOOK_187307</td>\n",
       "      <td>37.0</td>\n",
       "      <td>vermilion, ohio, usa</td>\n",
       "      <td>Embraced by the Light</td>\n",
       "      <td>Betty J. Eadie</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Bantam Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID     User-ID      Book-ID   Age              Location   \n",
       "0  TEST_000000  USER_00008  BOOK_047966  37.0  vermilion, ohio, usa  \\\n",
       "1  TEST_000001  USER_00008  BOOK_119494  37.0  vermilion, ohio, usa   \n",
       "2  TEST_000002  USER_00008  BOOK_151775  37.0  vermilion, ohio, usa   \n",
       "3  TEST_000003  USER_00008  BOOK_176255  37.0  vermilion, ohio, usa   \n",
       "4  TEST_000004  USER_00008  BOOK_187307  37.0  vermilion, ohio, usa   \n",
       "\n",
       "                                          Book-Title     Book-Author   \n",
       "0                 Birds of Prey: A Novel of Suspense      J.A. Jance  \\\n",
       "1                                    Midnight Voices       JOHN SAUL   \n",
       "2  Breaking Free : A Prescription for Personal an...  David M.  Noer   \n",
       "3                                     Bitter Harvest        Ann Rule   \n",
       "4                              Embraced by the Light  Betty J. Eadie   \n",
       "\n",
       "   Year-Of-Publication         Publisher  \n",
       "0               2002.0              Avon  \n",
       "1               2003.0  Ballantine Books  \n",
       "2               1996.0       Jossey-Bass  \n",
       "3               1999.0            Pocket  \n",
       "4               1994.0      Bantam Books  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('open/test.csv')\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get train, test array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Location</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000000</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_044368</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Road Taken</td>\n",
       "      <td>Rona Jaffe</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Mira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_000001</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_081205</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Macbeth (New Penguin Shakespeare)</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_000002</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_086781</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Waverley (Penguin English Library)</td>\n",
       "      <td>Walter Scott</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_000003</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_098622</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Mother Earth Father Sky</td>\n",
       "      <td>Sue Harrison</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Avon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_000004</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_180810</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>She Who Remembers</td>\n",
       "      <td>Linda Lay Shuler</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Signet Book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871388</th>\n",
       "      <td>TRAIN_871388</td>\n",
       "      <td>USER_92096</td>\n",
       "      <td>BOOK_081138</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>minneapolis, minnesota, usa</td>\n",
       "      <td>Healing Words: The Power of Prayer and the Pra...</td>\n",
       "      <td>Larry Dossey</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>Harpercollins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871389</th>\n",
       "      <td>TRAIN_871389</td>\n",
       "      <td>USER_92097</td>\n",
       "      <td>BOOK_258124</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>temple, texas, usa</td>\n",
       "      <td>The Salmon of Doubt: Hitchhiking the Galaxy On...</td>\n",
       "      <td>DOUGLAS ADAMS</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Harmony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871390</th>\n",
       "      <td>TRAIN_871390</td>\n",
       "      <td>USER_92098</td>\n",
       "      <td>BOOK_071848</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n",
       "      <td>J. K. Rowling</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Thorndike Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871391</th>\n",
       "      <td>TRAIN_871391</td>\n",
       "      <td>USER_92099</td>\n",
       "      <td>BOOK_252599</td>\n",
       "      <td>8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>maple grove, minnesota, usa</td>\n",
       "      <td>Heartbreak Hill: Anatomy of a Ryder Cup</td>\n",
       "      <td>Tim Rosaforte</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>St Martins Pr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871392</th>\n",
       "      <td>TRAIN_871392</td>\n",
       "      <td>USER_92100</td>\n",
       "      <td>BOOK_130798</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>castiglion fiorentino, toscana, italy</td>\n",
       "      <td>The Coffin Quilt: The Feud between the Hatfiel...</td>\n",
       "      <td>Ann Rinaldi</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Harcourt Children's Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>871393 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID     User-ID      Book-ID  Book-Rating   Age   \n",
       "0       TRAIN_000000  USER_00000  BOOK_044368            8  23.0  \\\n",
       "1       TRAIN_000001  USER_00000  BOOK_081205            8  23.0   \n",
       "2       TRAIN_000002  USER_00000  BOOK_086781            0  23.0   \n",
       "3       TRAIN_000003  USER_00000  BOOK_098622            0  23.0   \n",
       "4       TRAIN_000004  USER_00000  BOOK_180810            8  23.0   \n",
       "...              ...         ...          ...          ...   ...   \n",
       "871388  TRAIN_871388  USER_92096  BOOK_081138            0  34.0   \n",
       "871389  TRAIN_871389  USER_92097  BOOK_258124            0  35.0   \n",
       "871390  TRAIN_871390  USER_92098  BOOK_071848            0  45.0   \n",
       "871391  TRAIN_871391  USER_92099  BOOK_252599            8  43.0   \n",
       "871392  TRAIN_871392  USER_92100  BOOK_130798            0  35.0   \n",
       "\n",
       "                                     Location   \n",
       "0            sackville, new brunswick, canada  \\\n",
       "1            sackville, new brunswick, canada   \n",
       "2            sackville, new brunswick, canada   \n",
       "3            sackville, new brunswick, canada   \n",
       "4            sackville, new brunswick, canada   \n",
       "...                                       ...   \n",
       "871388            minneapolis, minnesota, usa   \n",
       "871389                     temple, texas, usa   \n",
       "871390                ottawa, ontario, canada   \n",
       "871391            maple grove, minnesota, usa   \n",
       "871392  castiglion fiorentino, toscana, italy   \n",
       "\n",
       "                                               Book-Title   \n",
       "0                                              Road Taken  \\\n",
       "1                       Macbeth (New Penguin Shakespeare)   \n",
       "2                      Waverley (Penguin English Library)   \n",
       "3                                 Mother Earth Father Sky   \n",
       "4                                       She Who Remembers   \n",
       "...                                                   ...   \n",
       "871388  Healing Words: The Power of Prayer and the Pra...   \n",
       "871389  The Salmon of Doubt: Hitchhiking the Galaxy On...   \n",
       "871390  Harry Potter and the Prisoner of Azkaban (Book 3)   \n",
       "871391            Heartbreak Hill: Anatomy of a Ryder Cup   \n",
       "871392  The Coffin Quilt: The Feud between the Hatfiel...   \n",
       "\n",
       "                Book-Author  Year-Of-Publication                  Publisher  \n",
       "0                Rona Jaffe               2001.0                       Mira  \n",
       "1       William Shakespeare               1981.0              Penguin Books  \n",
       "2              Walter Scott               1981.0              Penguin Books  \n",
       "3              Sue Harrison               1991.0                       Avon  \n",
       "4          Linda Lay Shuler               1989.0                Signet Book  \n",
       "...                     ...                  ...                        ...  \n",
       "871388         Larry Dossey               1993.0              Harpercollins  \n",
       "871389        DOUGLAS ADAMS               2002.0                    Harmony  \n",
       "871390        J. K. Rowling               2000.0            Thorndike Press  \n",
       "871391        Tim Rosaforte               1996.0              St Martins Pr  \n",
       "871392          Ann Rinaldi               1999.0  Harcourt Children's Books  \n",
       "\n",
       "[871393 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유저 정보\n",
    "\n",
    "### 나이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.49875233074745\n"
     ]
    }
   ],
   "source": [
    "Age_scaled = train_df['Age'].apply(lambda x: x if x <= 100 else np.nan)\n",
    "user_mean = Age_scaled.mean()\n",
    "print(user_mean)\n",
    "train_df['Age_scaled'] = Age_scaled.fillna(user_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Age_scaled'] = test_df['Age'].apply(lambda x: x if x <= 100 else np.nan).fillna(user_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((871393, 1), (159621, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_age = scaler.fit_transform(train_df[['Age_scaled']])\n",
    "test_age = scaler.transform(test_df[['Age_scaled']])\n",
    "\n",
    "train_age.shape, test_age.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 국가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83256, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER_00000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USER_00001</td>\n",
       "      <td>35.0</td>\n",
       "      <td>wake forest, north carolina, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USER_00002</td>\n",
       "      <td>35.0</td>\n",
       "      <td>minneapolis, minnesota, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USER_00003</td>\n",
       "      <td>24.0</td>\n",
       "      <td>magdeburg, sachsen-anhalt, germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>USER_00004</td>\n",
       "      <td>35.0</td>\n",
       "      <td>new york, new york, usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User-ID   Age                            Location\n",
       "0   USER_00000  23.0    sackville, new brunswick, canada\n",
       "8   USER_00001  35.0    wake forest, north carolina, usa\n",
       "11  USER_00002  35.0         minneapolis, minnesota, usa\n",
       "12  USER_00003  24.0  magdeburg, sachsen-anhalt, germany\n",
       "34  USER_00004  35.0             new york, new york, usa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = train_df[['User-ID', 'Age', 'Location']].drop_duplicates('User-ID', keep='first')\n",
    "print(user_df.shape)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['Country'] = user_df['Location'].apply(lambda x: x.split(',')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_df['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# 제거할 문장부호\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# 문장부호가 제거된 문자열을 반환하는 함수\n",
    "def remove_punctuations(text):\n",
    "    result = ''\n",
    "    if not pd.isna(text):\n",
    "        result = ''.join(char for char in text if char not in punctuations)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['Country'] = user_df['Country'].str.strip().replace('', np.nan).replace('n/a', np.nan).replace('nan', np.nan)\n",
    "user_df['Country'] = user_df['Country'].apply(lambda x: remove_punctuations(x))\n",
    "user_df['Country'] = user_df['Country'].str.strip().replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['usa', 'canada', 'germany', 'united kingdom', 'australia', 'spain',\n",
       "       'italy', 'france', 'new zealand', 'switzerland', 'netherlands',\n",
       "       'portugal', 'austria', 'malaysia', 'sweden', 'finland', 'ireland',\n",
       "       'singapore', 'brazil', 'belgium', 'denmark', 'argentina', 'philippines',\n",
       "       'mexico', 'japan', 'norway', 'israel', 'india', 'china', 'south africa',\n",
       "       'poland', 'greece', 'romania', 'south korea', 'luxembourg', 'turkey',\n",
       "       'hong kong', 'chile', 'costa rica', 'iran', 'slovenia',\n",
       "       'czech republic', 'iceland', 'indonesia', 'egypt', 'bulgaria',\n",
       "       'croatia', 'hungary', 'taiwan', 'united states', 'slovakia'],\n",
       "      dtype='object', name='Country')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = user_df['Country'].value_counts()[user_df['Country'].value_counts() > 10].index\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "united states -> usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(categories=[list(countries.values)], handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_location_to_country(location):\n",
    "    country = location.split(',')[-1].strip()\n",
    "    if not pd.isna(country):\n",
    "        if country in ['', 'n/a', 'nan']:\n",
    "            country = np.nan\n",
    "        country = remove_punctuations(country).strip()\n",
    "        if country in ['', 'n/a', 'nan']:\n",
    "            country = np.nan\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Country'] = train_df['Location'].apply(lambda x: preproc_location_to_country(x))\n",
    "test_df['Country'] = test_df['Location'].apply(lambda x: preproc_location_to_country(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['canada'],\n",
       "       ['canada'],\n",
       "       ['canada'],\n",
       "       ...,\n",
       "       ['canada'],\n",
       "       ['usa'],\n",
       "       ['italy']], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['Country']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((871393, 51), (159621, 51))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_countries = encoder.fit_transform(train_df[['Country']]).toarray()\n",
    "test_countries = encoder.transform(test_df[['Country']]).toarray()\n",
    "\n",
    "train_countries.shape, test_countries.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도서 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243441, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-ID</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOOK_044368</td>\n",
       "      <td>Road Taken</td>\n",
       "      <td>Rona Jaffe</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Mira</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOOK_081205</td>\n",
       "      <td>Macbeth (New Penguin Shakespeare)</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOOK_086781</td>\n",
       "      <td>Waverley (Penguin English Library)</td>\n",
       "      <td>Walter Scott</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOOK_098622</td>\n",
       "      <td>Mother Earth Father Sky</td>\n",
       "      <td>Sue Harrison</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Avon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOOK_180810</td>\n",
       "      <td>She Who Remembers</td>\n",
       "      <td>Linda Lay Shuler</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Signet Book</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Book-ID                          Book-Title          Book-Author   \n",
       "0  BOOK_044368                          Road Taken           Rona Jaffe  \\\n",
       "1  BOOK_081205   Macbeth (New Penguin Shakespeare)  William Shakespeare   \n",
       "2  BOOK_086781  Waverley (Penguin English Library)         Walter Scott   \n",
       "3  BOOK_098622             Mother Earth Father Sky         Sue Harrison   \n",
       "4  BOOK_180810                   She Who Remembers     Linda Lay Shuler   \n",
       "\n",
       "   Year-Of-Publication      Publisher  Book-Rating  \n",
       "0               2001.0           Mira            8  \n",
       "1               1981.0  Penguin Books            8  \n",
       "2               1981.0  Penguin Books            0  \n",
       "3               1991.0           Avon            0  \n",
       "4               1989.0    Signet Book            8  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df = train_df[['Book-ID', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Book-Rating']].drop_duplicates('Book-ID', keep='first')\n",
    "print(book_df.shape)\n",
    "book_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100개 이상의 책이 있는 출판사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Harlequin', 'Silhouette', 'Pocket', 'Ballantine Books', 'Bantam Books',\n",
       "       'Scholastic', 'Simon &amp; Schuster', 'Penguin Books',\n",
       "       'Berkley Publishing Group', 'Warner Books',\n",
       "       ...\n",
       "       'Diogenes', 'Droemer Knaur', 'Thorsons Publishers', 'Faber &amp; Faber',\n",
       "       'Flammarion', 'Fawcett', 'Dorling Kindersley', 'Scholastic Library Pub',\n",
       "       'G. P. Putnam's Sons', 'Rutledge Hill Press'],\n",
       "      dtype='object', name='Publisher', length=368)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publishers = book_df['Publisher'].value_counts()[book_df['Publisher'].value_counts() > 100].index\n",
    "publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((871393, 368), (159621, 368))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(categories=[list(publishers.values)], handle_unknown='ignore')\n",
    "\n",
    "train_publisher = encoder.fit_transform(train_df[['Publisher']]).toarray()\n",
    "test_publisher = encoder.transform(test_df[['Publisher']]).toarray()\n",
    "\n",
    "train_publisher.shape, test_publisher.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100개 이상의 책을 낸 작가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Agatha Christie', 'William Shakespeare', 'Stephen King',\n",
       "       'Ann M. Martin', 'Francine Pascal', 'Carolyn Keene', 'Isaac Asimov',\n",
       "       'Barbara Cartland', 'Nora Roberts', 'Charles Dickens', 'R. L. Stine',\n",
       "       'Not Applicable (Na )', 'Piers Anthony', 'Mark Twain',\n",
       "       'Marion Zimmer Bradley', 'Jane Austen', 'Terry Pratchett',\n",
       "       'Mary Higgins Clark', 'Franklin W. Dixon', 'Janet Dailey', 'Roald Dahl',\n",
       "       'Dick Francis', 'Anne McCaffrey', 'J. R. R. Tolkien', 'Tom Clancy',\n",
       "       'Nathaniel Hawthorne', 'John Steinbeck', 'Danielle Steel',\n",
       "       'Diana Palmer', 'Fern Michaels', 'Enid Blyton', 'Sandra Brown',\n",
       "       'Don Pendleton', 'Ed McBain', 'L. Frank Baum', 'R.L. Stine',\n",
       "       'Jim Davis', 'Jayne Ann Krentz', 'Andre Norton', 'Stan Berenstain',\n",
       "       'John Grisham', 'Elmore Leonard', 'James A. Michener', 'C. S. Lewis',\n",
       "       'Orson Scott Card', 'Robert Ludlum', 'Oscar Wilde',\n",
       "       'Robert Louis Stevenson', 'Beatrix Potter', 'Jack Canfield',\n",
       "       'Alan Dean Foster', 'Barbara Delinsky', 'Jude Deveraux', 'Henry James',\n",
       "       'Catherine Coulter', 'Clive Cussler', 'Linda Howard', 'Golden Books',\n",
       "       'Anne Rice', 'Thomas Hardy', 'Louisa May Alcott', 'Louis L'Amour',\n",
       "       'Georges Simenon', 'Ken Follett', 'Ray Bradbury', 'Jack London',\n",
       "       'Margaret Weis', 'Robert A. Heinlein', 'Larry Niven',\n",
       "       'Lawrence Sanders', 'James Patterson', 'Ruth Rendell', 'Betty Neels',\n",
       "       'Edith Wharton', 'Beverly Cleary', 'Robin Cook', 'Lewis Carroll',\n",
       "       'Ursula K. Le Guin', 'Frank Herbert', 'Joyce Carol Oates',\n",
       "       'Robert Silverberg', 'Rudyard Kipling', 'Ellis Peters',\n",
       "       'Edgar Allan Poe', 'Christopher Pike'],\n",
       "      dtype='object', name='Book-Author')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = book_df['Book-Author'].value_counts()[book_df['Book-Author'].value_counts() > 100].index\n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((871393, 85), (159621, 85))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(categories=[list(authors.values)], handle_unknown='ignore')\n",
    "\n",
    "train_author = encoder.fit_transform(train_df[['Book-Author']]).toarray()\n",
    "test_author = encoder.transform(test_df[['Book-Author']]).toarray()\n",
    "\n",
    "train_author.shape, test_author.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 책 제목 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_title(title):\n",
    "    # remove noise\n",
    "    tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "    tokens = tokenizer.tokenize(title.lower())\n",
    "    # print(tokens)\n",
    "\n",
    "    # remove stopwords\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    result = [word for word in tokens if word not in english_stops]\n",
    "    # print(result)\n",
    "    \n",
    "    # stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_result = [stemmer.stem(token) for token in result]\n",
    "    # print(stemmed_result)\n",
    "    \n",
    "    return stemmed_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 871393/871393 [02:58<00:00, 4871.77it/s]\n"
     ]
    }
   ],
   "source": [
    "train_titles = []\n",
    "for title in tqdm(train_df['Book-Title']):\n",
    "    train_titles.append(preproc_title(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159621/159621 [00:33<00:00, 4809.32it/s]\n"
     ]
    }
   ],
   "source": [
    "test_titles = []\n",
    "for title in tqdm(test_df['Book-Title']):\n",
    "    test_titles.append(preproc_title(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 14:45:16.825867: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-07 14:45:16.969115: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-07 14:45:17.625184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-07 14:45:17.625384: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-07 14:45:17.625398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 300\n",
    "maxlen = 40\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='UNK')\n",
    "tokenizer.fit_on_texts(train_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title = tokenizer.texts_to_sequences(train_titles)\n",
    "train_title = pad_sequences(train_title, maxlen=maxlen, truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_title = tokenizer.texts_to_sequences(test_titles)\n",
    "test_title = pad_sequences(test_title, maxlen=maxlen, truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((871393, 40), (159621, 40))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_title.shape, test_title.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 과정이 필요하다. train, test 모두"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(871393, 545)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.concatenate([train_age, train_countries, train_author, train_publisher, train_title], axis=-1)\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159621, 545)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = np.concatenate([test_age, test_countries, test_author, test_publisher, test_title], axis=-1)\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df[['Book-Rating']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_model(input_dims, alpha):\n",
    "    # define input tensor\n",
    "    input_layer = tf.keras.Input(shape=input_dims, dtype=tf.float32)\n",
    "\n",
    "    # # hidden layer\n",
    "    # x = tf.keras.layers.Dense(\n",
    "    #     1024, activation='relu', \n",
    "    #     kernel_regularizer=tf.keras.regularizers.l2(alpha))(input_layer)\n",
    "\n",
    "    # hidden layer\n",
    "    x = tf.keras.layers.Dense(\n",
    "        256, activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(alpha))(input_layer)\n",
    "    \n",
    "    # hidden layer\n",
    "    x = tf.keras.layers.Dense(\n",
    "        128, activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(alpha))(x)\n",
    "\n",
    "    # hidden layer\n",
    "    x = tf.keras.layers.Dense(\n",
    "        64, activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(alpha))(x)\n",
    "    \n",
    "    # hidden layer\n",
    "    x = tf.keras.layers.Dense(\n",
    "        32, activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(alpha))(x)\n",
    "    \n",
    "    # output layer\n",
    "    x = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(input_layer, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 1000\n",
    "epochs = 200\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    model = build_custom_model(input_dims=train_X.shape[1:], alpha=alpha)\n",
    "\n",
    "    # define optimizer Adam\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # model compile\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 545)]             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               139776    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,041\n",
      "Trainable params: 183,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "785/785 [==============================] - 10s 8ms/step - loss: 18.7528 - mse: 16.6321 - val_loss: 16.5852 - val_mse: 14.9727\n",
      "Epoch 2/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 16.3995 - mse: 14.9048 - val_loss: 16.2179 - val_mse: 14.7983\n",
      "Epoch 3/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 16.0985 - mse: 14.7242 - val_loss: 15.9996 - val_mse: 14.6655\n",
      "Epoch 4/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.9505 - mse: 14.6502 - val_loss: 15.8598 - val_mse: 14.5921\n",
      "Epoch 5/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.8441 - mse: 14.6049 - val_loss: 15.7816 - val_mse: 14.5698\n",
      "Epoch 6/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.7589 - mse: 14.5719 - val_loss: 15.7101 - val_mse: 14.5482\n",
      "Epoch 7/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.6876 - mse: 14.5475 - val_loss: 15.6640 - val_mse: 14.5460\n",
      "Epoch 8/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.6307 - mse: 14.5325 - val_loss: 15.5996 - val_mse: 14.5212\n",
      "Epoch 9/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.5786 - mse: 14.5185 - val_loss: 15.6395 - val_mse: 14.5973\n",
      "Epoch 10/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.5319 - mse: 14.5064 - val_loss: 15.5079 - val_mse: 14.4994\n",
      "Epoch 11/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.4936 - mse: 14.5005 - val_loss: 15.4956 - val_mse: 14.5182\n",
      "Epoch 12/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.4475 - mse: 14.4848 - val_loss: 15.4767 - val_mse: 14.5282\n",
      "Epoch 13/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.4165 - mse: 14.4818 - val_loss: 15.4530 - val_mse: 14.5323\n",
      "Epoch 14/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.3795 - mse: 14.4716 - val_loss: 15.4430 - val_mse: 14.5485\n",
      "Epoch 15/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.3510 - mse: 14.4686 - val_loss: 15.3837 - val_mse: 14.5141\n",
      "Epoch 16/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.3196 - mse: 14.4616 - val_loss: 15.3807 - val_mse: 14.5344\n",
      "Epoch 17/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.2934 - mse: 14.4582 - val_loss: 15.4170 - val_mse: 14.5933\n",
      "Epoch 18/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.2650 - mse: 14.4515 - val_loss: 15.3260 - val_mse: 14.5237\n",
      "Epoch 19/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.2390 - mse: 14.4465 - val_loss: 15.3085 - val_mse: 14.5264\n",
      "Epoch 20/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.2083 - mse: 14.4357 - val_loss: 15.3322 - val_mse: 14.5691\n",
      "Epoch 21/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.1928 - mse: 14.4386 - val_loss: 15.2037 - val_mse: 14.4592\n",
      "Epoch 22/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.1694 - mse: 14.4335 - val_loss: 15.2542 - val_mse: 14.5274\n",
      "Epoch 23/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.1465 - mse: 14.4276 - val_loss: 15.1791 - val_mse: 14.4687\n",
      "Epoch 24/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.1321 - mse: 14.4296 - val_loss: 15.1768 - val_mse: 14.4828\n",
      "Epoch 25/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.1042 - mse: 14.4175 - val_loss: 15.1514 - val_mse: 14.4725\n",
      "Epoch 26/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.0886 - mse: 14.4168 - val_loss: 15.1789 - val_mse: 14.5149\n",
      "Epoch 27/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.0721 - mse: 14.4150 - val_loss: 15.1304 - val_mse: 14.4806\n",
      "Epoch 28/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.0544 - mse: 14.4111 - val_loss: 15.1132 - val_mse: 14.4772\n",
      "Epoch 29/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 15.0403 - mse: 14.4106 - val_loss: 15.0852 - val_mse: 14.4624\n",
      "Epoch 30/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.0246 - mse: 14.4079 - val_loss: 15.1088 - val_mse: 14.4985\n",
      "Epoch 31/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 15.0033 - mse: 14.3989 - val_loss: 15.0515 - val_mse: 14.4534\n",
      "Epoch 32/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.9866 - mse: 14.3941 - val_loss: 15.0793 - val_mse: 14.4929\n",
      "Epoch 33/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.9804 - mse: 14.3995 - val_loss: 15.0751 - val_mse: 14.5000\n",
      "Epoch 34/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.9650 - mse: 14.3951 - val_loss: 15.0100 - val_mse: 14.4460\n",
      "Epoch 35/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.9513 - mse: 14.3924 - val_loss: 15.0171 - val_mse: 14.4636\n",
      "Epoch 36/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.9420 - mse: 14.3934 - val_loss: 14.9867 - val_mse: 14.4433\n",
      "Epoch 37/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.9310 - mse: 14.3921 - val_loss: 15.0697 - val_mse: 14.5363\n",
      "Epoch 38/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.9216 - mse: 14.3927 - val_loss: 14.9556 - val_mse: 14.4319\n",
      "Epoch 39/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.9026 - mse: 14.3831 - val_loss: 14.9703 - val_mse: 14.4560\n",
      "Epoch 40/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.8895 - mse: 14.3794 - val_loss: 14.9912 - val_mse: 14.4858\n",
      "Epoch 41/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.8823 - mse: 14.3812 - val_loss: 14.9259 - val_mse: 14.4293\n",
      "Epoch 42/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.8713 - mse: 14.3785 - val_loss: 14.9634 - val_mse: 14.4753\n",
      "Epoch 43/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.8655 - mse: 14.3814 - val_loss: 14.9555 - val_mse: 14.4754\n",
      "Epoch 44/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.8537 - mse: 14.3774 - val_loss: 14.9736 - val_mse: 14.5017\n",
      "Epoch 45/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.8444 - mse: 14.3760 - val_loss: 14.9285 - val_mse: 14.4642\n",
      "Epoch 46/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.8332 - mse: 14.3725 - val_loss: 14.9004 - val_mse: 14.4438\n",
      "Epoch 47/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.8270 - mse: 14.3735 - val_loss: 14.9366 - val_mse: 14.4871\n",
      "Epoch 48/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.8194 - mse: 14.3731 - val_loss: 14.8810 - val_mse: 14.4384\n",
      "Epoch 49/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.8072 - mse: 14.3677 - val_loss: 14.8824 - val_mse: 14.4469\n",
      "Epoch 50/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.7983 - mse: 14.3657 - val_loss: 14.8856 - val_mse: 14.4565\n",
      "Epoch 51/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.7903 - mse: 14.3642 - val_loss: 14.8856 - val_mse: 14.4631\n",
      "Epoch 52/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.7895 - mse: 14.3698 - val_loss: 14.9740 - val_mse: 14.5578\n",
      "Epoch 53/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7762 - mse: 14.3625 - val_loss: 14.8563 - val_mse: 14.4461\n",
      "Epoch 54/200\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 14.7734 - mse: 14.3659 - val_loss: 14.8375 - val_mse: 14.4332\n",
      "Epoch 55/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7607 - mse: 14.3592 - val_loss: 14.8073 - val_mse: 14.4088\n",
      "Epoch 56/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7622 - mse: 14.3662 - val_loss: 14.8364 - val_mse: 14.4437\n",
      "Epoch 57/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7462 - mse: 14.3559 - val_loss: 14.8439 - val_mse: 14.4565\n",
      "Epoch 58/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.7454 - mse: 14.3605 - val_loss: 14.8354 - val_mse: 14.4536\n",
      "Epoch 59/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.7366 - mse: 14.3572 - val_loss: 14.8010 - val_mse: 14.4243\n",
      "Epoch 60/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7296 - mse: 14.3554 - val_loss: 14.7943 - val_mse: 14.4228\n",
      "Epoch 61/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7203 - mse: 14.3510 - val_loss: 14.8539 - val_mse: 14.4876\n",
      "Epoch 62/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7169 - mse: 14.3528 - val_loss: 14.8019 - val_mse: 14.4407\n",
      "Epoch 63/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7125 - mse: 14.3534 - val_loss: 14.9109 - val_mse: 14.5546\n",
      "Epoch 64/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7002 - mse: 14.3460 - val_loss: 14.8802 - val_mse: 14.5284\n",
      "Epoch 65/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.7031 - mse: 14.3535 - val_loss: 14.7840 - val_mse: 14.4371\n",
      "Epoch 66/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.6963 - mse: 14.3514 - val_loss: 14.7951 - val_mse: 14.4526\n",
      "Epoch 67/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.6960 - mse: 14.3555 - val_loss: 14.8183 - val_mse: 14.4802\n",
      "Epoch 68/200\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 14.6770 - mse: 14.3409 - val_loss: 14.8024 - val_mse: 14.4686\n",
      "Epoch 69/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.6812 - mse: 14.3491 - val_loss: 14.8268 - val_mse: 14.4973\n",
      "Epoch 70/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6754 - mse: 14.3478 - val_loss: 14.7693 - val_mse: 14.4440\n",
      "Epoch 71/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.6691 - mse: 14.3456 - val_loss: 14.7725 - val_mse: 14.4512\n",
      "Epoch 72/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.6688 - mse: 14.3492 - val_loss: 14.7798 - val_mse: 14.4625\n",
      "Epoch 73/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.6608 - mse: 14.3450 - val_loss: 14.7299 - val_mse: 14.4166\n",
      "Epoch 74/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6551 - mse: 14.3434 - val_loss: 14.7652 - val_mse: 14.4554\n",
      "Epoch 75/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6514 - mse: 14.3433 - val_loss: 14.7357 - val_mse: 14.4295\n",
      "Epoch 76/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6437 - mse: 14.3390 - val_loss: 14.7303 - val_mse: 14.4279\n",
      "Epoch 77/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6404 - mse: 14.3394 - val_loss: 14.8061 - val_mse: 14.5072\n",
      "Epoch 78/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6265 - mse: 14.3289 - val_loss: 14.7239 - val_mse: 14.4284\n",
      "Epoch 79/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.6262 - mse: 14.3320 - val_loss: 14.7111 - val_mse: 14.4189\n",
      "Epoch 80/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6271 - mse: 14.3364 - val_loss: 14.7388 - val_mse: 14.4499\n",
      "Epoch 81/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6201 - mse: 14.3324 - val_loss: 14.7797 - val_mse: 14.4941\n",
      "Epoch 82/200\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 14.6185 - mse: 14.3340 - val_loss: 14.7329 - val_mse: 14.4501\n",
      "Epoch 83/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6115 - mse: 14.3300 - val_loss: 14.7300 - val_mse: 14.4499\n",
      "Epoch 84/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6067 - mse: 14.3279 - val_loss: 14.7091 - val_mse: 14.4321\n",
      "Epoch 85/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.6051 - mse: 14.3291 - val_loss: 14.7485 - val_mse: 14.4742\n",
      "Epoch 86/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6013 - mse: 14.3282 - val_loss: 14.7008 - val_mse: 14.4293\n",
      "Epoch 87/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.6050 - mse: 14.3346 - val_loss: 14.6651 - val_mse: 14.3963\n",
      "Epoch 88/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5930 - mse: 14.3253 - val_loss: 14.7361 - val_mse: 14.4697\n",
      "Epoch 89/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5953 - mse: 14.3302 - val_loss: 14.6855 - val_mse: 14.4216\n",
      "Epoch 90/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5918 - mse: 14.3290 - val_loss: 14.7701 - val_mse: 14.5087\n",
      "Epoch 91/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5884 - mse: 14.3279 - val_loss: 14.7808 - val_mse: 14.5221\n",
      "Epoch 92/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.5847 - mse: 14.3268 - val_loss: 14.6998 - val_mse: 14.4435\n",
      "Epoch 93/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.5830 - mse: 14.3276 - val_loss: 14.7406 - val_mse: 14.4866\n",
      "Epoch 94/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.5787 - mse: 14.3256 - val_loss: 14.6852 - val_mse: 14.4332\n",
      "Epoch 95/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5762 - mse: 14.3254 - val_loss: 14.6792 - val_mse: 14.4298\n",
      "Epoch 96/200\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 14.5706 - mse: 14.3220 - val_loss: 14.7546 - val_mse: 14.5073\n",
      "Epoch 97/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5669 - mse: 14.3205 - val_loss: 14.7106 - val_mse: 14.4655\n",
      "Epoch 98/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5698 - mse: 14.3254 - val_loss: 14.6507 - val_mse: 14.4076\n",
      "Epoch 99/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5615 - mse: 14.3192 - val_loss: 14.6833 - val_mse: 14.4421\n",
      "Epoch 100/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5627 - mse: 14.3223 - val_loss: 14.7122 - val_mse: 14.4730\n",
      "Epoch 101/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5573 - mse: 14.3190 - val_loss: 14.6583 - val_mse: 14.4210\n",
      "Epoch 102/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.5575 - mse: 14.3209 - val_loss: 14.7218 - val_mse: 14.4865\n",
      "Epoch 103/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5557 - mse: 14.3210 - val_loss: 14.6630 - val_mse: 14.4296\n",
      "Epoch 104/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5535 - mse: 14.3208 - val_loss: 14.7011 - val_mse: 14.4695\n",
      "Epoch 105/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5484 - mse: 14.3174 - val_loss: 14.6691 - val_mse: 14.4393\n",
      "Epoch 106/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5448 - mse: 14.3156 - val_loss: 14.7359 - val_mse: 14.5078\n",
      "Epoch 107/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5448 - mse: 14.3173 - val_loss: 14.6635 - val_mse: 14.4370\n",
      "Epoch 108/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5408 - mse: 14.3148 - val_loss: 14.7552 - val_mse: 14.5304\n",
      "Epoch 109/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5386 - mse: 14.3143 - val_loss: 14.6518 - val_mse: 14.4288\n",
      "Epoch 110/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5380 - mse: 14.3154 - val_loss: 14.6531 - val_mse: 14.4316\n",
      "Epoch 111/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5377 - mse: 14.3167 - val_loss: 14.6539 - val_mse: 14.4338\n",
      "Epoch 112/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5296 - mse: 14.3101 - val_loss: 14.6826 - val_mse: 14.4641\n",
      "Epoch 113/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5346 - mse: 14.3164 - val_loss: 14.6433 - val_mse: 14.4262\n",
      "Epoch 114/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5244 - mse: 14.3077 - val_loss: 14.6362 - val_mse: 14.4208\n",
      "Epoch 115/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5229 - mse: 14.3078 - val_loss: 14.6337 - val_mse: 14.4196\n",
      "Epoch 116/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5268 - mse: 14.3133 - val_loss: 14.6920 - val_mse: 14.4792\n",
      "Epoch 117/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5230 - mse: 14.3106 - val_loss: 14.6415 - val_mse: 14.4301\n",
      "Epoch 118/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5175 - mse: 14.3065 - val_loss: 14.6301 - val_mse: 14.4202\n",
      "Epoch 119/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.5194 - mse: 14.3099 - val_loss: 14.6456 - val_mse: 14.4368\n",
      "Epoch 120/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5148 - mse: 14.3064 - val_loss: 14.6732 - val_mse: 14.4658\n",
      "Epoch 121/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5142 - mse: 14.3072 - val_loss: 14.6722 - val_mse: 14.4657\n",
      "Epoch 122/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5172 - mse: 14.3113 - val_loss: 14.6841 - val_mse: 14.4791\n",
      "Epoch 123/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5123 - mse: 14.3077 - val_loss: 14.6589 - val_mse: 14.4549\n",
      "Epoch 124/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5078 - mse: 14.3044 - val_loss: 14.7120 - val_mse: 14.5092\n",
      "Epoch 125/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.5056 - mse: 14.3032 - val_loss: 14.6661 - val_mse: 14.4647\n",
      "Epoch 126/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5074 - mse: 14.3064 - val_loss: 14.6420 - val_mse: 14.4415\n",
      "Epoch 127/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5073 - mse: 14.3072 - val_loss: 14.6189 - val_mse: 14.4196\n",
      "Epoch 128/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.5049 - mse: 14.3061 - val_loss: 14.6781 - val_mse: 14.4798\n",
      "Epoch 129/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.5048 - mse: 14.3068 - val_loss: 14.6341 - val_mse: 14.4369\n",
      "Epoch 130/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4987 - mse: 14.3020 - val_loss: 14.6033 - val_mse: 14.4073\n",
      "Epoch 131/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4995 - mse: 14.3037 - val_loss: 14.6806 - val_mse: 14.4854\n",
      "Epoch 132/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4968 - mse: 14.3020 - val_loss: 14.6407 - val_mse: 14.4466\n",
      "Epoch 133/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4947 - mse: 14.3009 - val_loss: 14.6247 - val_mse: 14.4316\n",
      "Epoch 134/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4869 - mse: 14.2940 - val_loss: 14.6355 - val_mse: 14.4435\n",
      "Epoch 135/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4953 - mse: 14.3036 - val_loss: 14.7261 - val_mse: 14.5350\n",
      "Epoch 136/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4895 - mse: 14.2986 - val_loss: 14.6372 - val_mse: 14.4469\n",
      "Epoch 137/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4817 - mse: 14.2918 - val_loss: 14.6908 - val_mse: 14.5017\n",
      "Epoch 138/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4857 - mse: 14.2969 - val_loss: 14.5942 - val_mse: 14.4059\n",
      "Epoch 139/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4853 - mse: 14.2971 - val_loss: 14.6100 - val_mse: 14.4226\n",
      "Epoch 140/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4862 - mse: 14.2990 - val_loss: 14.6504 - val_mse: 14.4639\n",
      "Epoch 141/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4853 - mse: 14.2988 - val_loss: 14.6062 - val_mse: 14.4205\n",
      "Epoch 142/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4791 - mse: 14.2936 - val_loss: 14.6256 - val_mse: 14.4407\n",
      "Epoch 143/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4828 - mse: 14.2981 - val_loss: 14.6088 - val_mse: 14.4248\n",
      "Epoch 144/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4853 - mse: 14.3014 - val_loss: 14.6056 - val_mse: 14.4222\n",
      "Epoch 145/200\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 14.4788 - mse: 14.2957 - val_loss: 14.6060 - val_mse: 14.4236\n",
      "Epoch 146/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4744 - mse: 14.2920 - val_loss: 14.6268 - val_mse: 14.4450\n",
      "Epoch 147/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4792 - mse: 14.2976 - val_loss: 14.6719 - val_mse: 14.4909\n",
      "Epoch 148/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4709 - mse: 14.2901 - val_loss: 14.7186 - val_mse: 14.5384\n",
      "Epoch 149/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4716 - mse: 14.2916 - val_loss: 14.6106 - val_mse: 14.4312\n",
      "Epoch 150/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4708 - mse: 14.2915 - val_loss: 14.6066 - val_mse: 14.4280\n",
      "Epoch 151/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4715 - mse: 14.2928 - val_loss: 14.6250 - val_mse: 14.4471\n",
      "Epoch 152/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4673 - mse: 14.2894 - val_loss: 14.6216 - val_mse: 14.4443\n",
      "Epoch 153/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4686 - mse: 14.2914 - val_loss: 14.6750 - val_mse: 14.4984\n",
      "Epoch 154/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4700 - mse: 14.2934 - val_loss: 14.5942 - val_mse: 14.4181\n",
      "Epoch 155/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4683 - mse: 14.2924 - val_loss: 14.5832 - val_mse: 14.4078\n",
      "Epoch 156/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4618 - mse: 14.2865 - val_loss: 14.6457 - val_mse: 14.4709\n",
      "Epoch 157/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4625 - mse: 14.2878 - val_loss: 14.6186 - val_mse: 14.4445\n",
      "Epoch 158/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4645 - mse: 14.2905 - val_loss: 14.7335 - val_mse: 14.5600\n",
      "Epoch 159/200\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 14.4644 - mse: 14.2909 - val_loss: 14.6417 - val_mse: 14.4689\n",
      "Epoch 160/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4622 - mse: 14.2895 - val_loss: 14.6222 - val_mse: 14.4499\n",
      "Epoch 161/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4614 - mse: 14.2891 - val_loss: 14.5689 - val_mse: 14.3971\n",
      "Epoch 162/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4591 - mse: 14.2873 - val_loss: 14.5673 - val_mse: 14.3962\n",
      "Epoch 163/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4551 - mse: 14.2841 - val_loss: 14.5888 - val_mse: 14.4181\n",
      "Epoch 164/200\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 14.4499 - mse: 14.2793 - val_loss: 14.5943 - val_mse: 14.4242\n",
      "Epoch 165/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4533 - mse: 14.2832 - val_loss: 14.5850 - val_mse: 14.4155\n",
      "Epoch 166/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4464 - mse: 14.2769 - val_loss: 14.5935 - val_mse: 14.4245\n",
      "Epoch 167/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4522 - mse: 14.2832 - val_loss: 14.6541 - val_mse: 14.4856\n",
      "Epoch 168/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4509 - mse: 14.2823 - val_loss: 14.6175 - val_mse: 14.4494\n",
      "Epoch 169/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4499 - mse: 14.2819 - val_loss: 14.5926 - val_mse: 14.4251\n",
      "Epoch 170/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4558 - mse: 14.2884 - val_loss: 14.6179 - val_mse: 14.4508\n",
      "Epoch 171/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4467 - mse: 14.2796 - val_loss: 14.5932 - val_mse: 14.4268\n",
      "Epoch 172/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4452 - mse: 14.2787 - val_loss: 14.5941 - val_mse: 14.4281\n",
      "Epoch 173/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4428 - mse: 14.2768 - val_loss: 14.6522 - val_mse: 14.4867\n",
      "Epoch 174/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4438 - mse: 14.2784 - val_loss: 14.6691 - val_mse: 14.5041\n",
      "Epoch 175/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4450 - mse: 14.2799 - val_loss: 14.5706 - val_mse: 14.4059\n",
      "Epoch 176/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4388 - mse: 14.2740 - val_loss: 14.6123 - val_mse: 14.4481\n",
      "Epoch 177/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4408 - mse: 14.2767 - val_loss: 14.6550 - val_mse: 14.4912\n",
      "Epoch 178/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4384 - mse: 14.2746 - val_loss: 14.5666 - val_mse: 14.4033\n",
      "Epoch 179/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4428 - mse: 14.2793 - val_loss: 14.5689 - val_mse: 14.4059\n",
      "Epoch 180/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4407 - mse: 14.2776 - val_loss: 14.6005 - val_mse: 14.4379\n",
      "Epoch 181/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4402 - mse: 14.2774 - val_loss: 14.6032 - val_mse: 14.4411\n",
      "Epoch 182/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4381 - mse: 14.2759 - val_loss: 14.6084 - val_mse: 14.4467\n",
      "Epoch 183/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4312 - mse: 14.2694 - val_loss: 14.6062 - val_mse: 14.4447\n",
      "Epoch 184/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4320 - mse: 14.2706 - val_loss: 14.6412 - val_mse: 14.4803\n",
      "Epoch 185/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4355 - mse: 14.2744 - val_loss: 14.5807 - val_mse: 14.4203\n",
      "Epoch 186/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4324 - mse: 14.2718 - val_loss: 14.5618 - val_mse: 14.4016\n",
      "Epoch 187/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4327 - mse: 14.2725 - val_loss: 14.6381 - val_mse: 14.4782\n",
      "Epoch 188/200\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 14.4322 - mse: 14.2723 - val_loss: 14.5630 - val_mse: 14.4034\n",
      "Epoch 189/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4311 - mse: 14.2714 - val_loss: 14.5851 - val_mse: 14.4260\n",
      "Epoch 190/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4244 - mse: 14.2652 - val_loss: 14.5719 - val_mse: 14.4130\n",
      "Epoch 191/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4279 - mse: 14.2690 - val_loss: 14.6078 - val_mse: 14.4494\n",
      "Epoch 192/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4312 - mse: 14.2727 - val_loss: 14.5691 - val_mse: 14.4108\n",
      "Epoch 193/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4289 - mse: 14.2706 - val_loss: 14.5829 - val_mse: 14.4250\n",
      "Epoch 194/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4302 - mse: 14.2722 - val_loss: 14.5833 - val_mse: 14.4258\n",
      "Epoch 195/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4281 - mse: 14.2705 - val_loss: 14.5775 - val_mse: 14.4202\n",
      "Epoch 196/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4197 - mse: 14.2624 - val_loss: 14.5949 - val_mse: 14.4380\n",
      "Epoch 197/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4202 - mse: 14.2633 - val_loss: 14.6023 - val_mse: 14.4455\n",
      "Epoch 198/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4206 - mse: 14.2639 - val_loss: 14.6342 - val_mse: 14.4780\n",
      "Epoch 199/200\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 14.4282 - mse: 14.2719 - val_loss: 14.5639 - val_mse: 14.4080\n",
      "Epoch 200/200\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 14.4202 - mse: 14.2642 - val_loss: 14.5853 - val_mse: 14.4297\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, validation_split=.1, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27232/27232 [==============================] - 56s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.1950505],\n",
       "       [4.4594   ],\n",
       "       [3.4055123],\n",
       "       ...,\n",
       "       [4.846636 ],\n",
       "       [2.244918 ],\n",
       "       [3.3953724]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = model.predict(train_X)\n",
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4989/4989 [==============================] - 10s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.773722101525388"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = mean_squared_error(train_y, train_pred, squared=False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159616</th>\n",
       "      <td>TEST_159616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159617</th>\n",
       "      <td>TEST_159617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159618</th>\n",
       "      <td>TEST_159618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159619</th>\n",
       "      <td>TEST_159619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159620</th>\n",
       "      <td>TEST_159620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Book-Rating\n",
       "0       TEST_000000            0\n",
       "1       TEST_000001            0\n",
       "2       TEST_000002            0\n",
       "3       TEST_000003            0\n",
       "4       TEST_000004            0\n",
       "...             ...          ...\n",
       "159616  TEST_159616            0\n",
       "159617  TEST_159617            0\n",
       "159618  TEST_159618            0\n",
       "159619  TEST_159619            0\n",
       "159620  TEST_159620            0\n",
       "\n",
       "[159621 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission_df = pd.read_csv(\"open/sample_submission.csv\")\n",
    "sample_submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = 'title-wordembed2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_report(template, test_pred, mname):\n",
    "    template['Book-Rating'] = test_pred\n",
    "    now = dt.strftime(dt.now(), '%y-%m-%d')\n",
    "    template.to_csv(f'results/{mname}-{now}.csv', index=False)\n",
    "    \n",
    "make_report(sample_submission_df, test_pred, mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
